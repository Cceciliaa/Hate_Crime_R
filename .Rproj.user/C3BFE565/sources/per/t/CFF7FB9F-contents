### DPSS Programming in R
### Lecture 6 - Data Gathering and APIs
### Daniel Snow

library(tidyverse)

# Today we will use three new libraries that you will need to install first. Use install.packages("library_name") to install each one.

library(jsonlite)   # For reading raw JSON
library(tidycensus) # For downloading U.S. Census data
library(fredr)      # For downloading Federal Reserve data

###########################
####### API Overview ######
###########################

# In the policy world, you will often find yourself using data from a variety of sources. For demographic data, you'll often use data from the U.S. Census or the General Social Survey. For economic and labor data, you might use data from the Bureau of Labor Statistics (BLS) or the Federal Reserve. For local and state data, you'll likely use data from a data portal like the one set up by the City of Chicago.

# Typically, you don't need ALL of the data that these entities hold (the entirety of the Census Bureau's data is likely terabytes or petabytes in size), rather, you want to extract some small part of the data that you're interested in. An API (Application Programming Interface) allows you to query large datasets via the internet and return only the records you care about. This saves you time and saves bandwidth for the entity offering the API, since you only download the data you need.

# APIs are increasingly common. Most entities hosting large amounts of data use some sort of API to access it. Many government APIs are free and require only that you use an API key. However, not all APIs are free or public. There are plenty of paid APIs that provide some sort of specialized service (Google Maps comes to mind). Many companies use internal, private APIs that only employees can access.

# Today we will use two different API wrapper packages (tidycensus, fredr) to gather data and create plots. I will also walkthrough how an API request is typically structured so you can form and download your own requests without using a wrapper package.

##### U.S. Census API #####

# The Census API is HUGE in the policy world. It is used to gather the vast majority of demographic statistics about different places. Any time you see an article that says "Chicago's population is getting younger" or "California's population has increased in the past decade" it's likely using Census data.

# To use the Census API, you first need a free API key. Get one here:
# https://api.census.gov/data/key_signup.html

# Census API Documentation: https://www.census.gov/data/developers/updates/new-discovery-tool.html

# Census API base URL: https://api.census.gov/data.html

# Data dictionary of all codes: https://www.socialexplorer.com/data/metadata


# R has a very nice Census API wrapper that makes querying the Census API very easy. It returns a tidy dataframe with the variables and their estimates for whatever you request. The first step to using it is to pass your API key to the function census_api_key()

census_api_key("03ab2d6505a1b176b91412dad7ca0692866d7799", install=TRUE, overwrite=TRUE) # , install=TRUE

# We can see all the variables available from the census using load_variables()
vars_dc_2010 <- load_variables(2017, "acs5")

# Here we're getting the total number of people in rental units for all states in 2010
rentals_df <- get_decennial(
  geography = "state",
  variables = "H011004",
  year = 2010)

# We can expand this to get more than one variable at once
housing_df <- get_decennial(
  geography = "state",
  variables = c("H011004", "H004001"),
  year = 2010)

# We can also name each variable to make it easier to interpret
housing_df <- get_decennial(
  geography = "state",
  variables = c(renters = "H011004", total = "H011001"),
  year = 2010)

housing_df %>%
  spread(variable, value) %>%
  mutate(pct_renters = renters / total) %>%
  mutate(State = fct_reorder(factor(NAME), pct_renters)) %>%
ggplot() +
  geom_point(aes(x = pct_renters, y = State))

# The census, generally speaking, has two big surveys: the decennial census and the American Community Survey. Tidycensus has functions to query both

# The ACS can query at many different levels of geography
il_income_df <- get_acs(
  geography = "county",
  variables = c(medincome = "B19013_001"),
  state = "IL")

il_income_df %>%
  mutate(
    NAME = str_remove(NAME, " County, Illinois"),
    NAME = fct_reorder(NAME, estimate)
  ) %>%
  filter(
    NAME %in% c("Cook", "Kendall", "DuPage",
                "Lake", "Will", "Kane", "McHenry")
  ) %>%
ggplot(aes(x = estimate, y = NAME)) +
  geom_errorbarh(aes(xmin = estimate - moe, xmax = estimate + moe)) +
  geom_point(color = "#1215f3", size = 3) +
  labs(
    title = "Median household income by county in Chicagoland",
    subtitle = "2012-2016 American Community Survey",
    y = "",
    x = "ACS estimate (bars represent margin of error)"
  ) +
  theme_bw()

# QUESTION: Create a plot showing median income by state using tidycensus and data from the Census API.
acs_state_df <-
  get_acs(
  geography = "state",
  variables = c(medincome = "B19013_001"),
  year = 2015
)

acs_state_df %>%
  mutate(NAME = fct_reorder(NAME, estimate)) %>%
  ggplot(aes(x = estimate, y = NAME)) +
  geom_errorbarh(aes(xmin = estimate - moe, xmax = estimate + moe)) +
  geom_point(color = "#1215f3", size = 3) +
  labs(
    title = "Median household income by state",
    subtitle = "2012-2016 American Community Survey",
    y = "",
    x = "ACS estimate (bars represent margin of error)"
  ) +
  theme_bw()

# CHALLENGE: Create a plot showing white population change in Cook County over time, starting in 1990.

il_sex_df <- get_acs(
  geography = "county",
  variables = c(male = "B01001_002", total = "B01001_001"),
  state = "IL", geometry = TRUE)

il_sex_df %>%
  select(-moe) %>%
  spread(variable, estimate) %>%
  mutate(ratio = male / total) %>%
ggplot() +
  geom_sf(aes(fill = ratio))

il_race_df <- get_acs(
  geography = "tract",
  county = "031",
  variables = c(total = "B02001_001",
                white = "B02001_002",
                black = "B02001_003",
                asian = "B02001_005",
                latino = "B03002_012"),
  state = "IL", geometry = TRUE
)

il_race_df %>%
  mutate(total = ifelse(
    variable == "total", estimate, NA)
  ) %>%
  fill(total) %>%
  mutate(pct = estimate / total) %>%
  select(variable, pct) %>%
  filter(variable != "total") %>%
  ggplot() +
    geom_sf(aes(fill = pct, color = pct)) +
    viridis::scale_fill_viridis() +
    viridis::scale_color_viridis() +
    facet_wrap(vars(variable), nrow = 2)

##### Federal Reserve API #####

# Fed data is used for a wide variety of labor statistics and economics. If you've ever seen unemployment stats in the news, they probably used FRED to get them.

# FRED Base URL
## https://fred.stlouisfed.org/

# Adapted From Sam Boysel's Blog Post:
## http://sboysel.github.io/fredr/articles/fredr.html

# API key request URL
# https://research.stlouisfed.org/docs/api/api_key.html


# Just like with the Census API, we must request an enter an API key
fredr_set_key("886e21a6e31f73cc29e2d7bf896efc3e")

# Gather unemployment rate since the beginning of 2000
unemployment <- fredr(
  series_id = "UNRATE",
  observation_start = as.Date("2000-01-01")
  )

# Plot the unemployment data as a line (time series)
unemployment %>%
  ggplot(aes(x = date, y=  value)) +
  geom_line(color="#238912") +
  labs(
    title = "Unemployment Rate (2000-2019)",
    x = "Year",
    y = "Unemployment Rate (%)"
  ) +
  theme_bw()

# You can change the specifications of your query to get different units or time periods
fredr_series_observations(
  series_id = "UNRATE",
  observation_start = as.Date("2000-01-01"),
  frequency = "q",
  units = "pch"
  ) %>%
  ggplot(aes(x = date, y=  value)) +
  geom_line(color="#238912") +
  labs(
    title = "Unemployment Quarterly Percent Change (2000-2019)",
    x = "Year",
    y = "% Change in Unemployment"
  ) +
  theme_bw()

## What options can I change? See API documentation:
# https://research.stlouisfed.org/docs/api/fred/series_observations.html
fredr_docs(endpoint = "series/observations")

# The easiest way to find a series that you need is to start here: https://fred.stlouisfed.org/categories , then choose a category and then series from that category. The series ID will be the right-most part of the URL of whatever series you select

# CHALLENGE: Create a time-series visualization of seasonally-adjusted U.S. GDP, starting in 1980.


##### Querying Raw APIs #####

# Sometimes you will encounter an API that doesn't have a wrapper package. In such a case, you will need to query the API directly by modifying the URL of a given API endpoint. This sounds hard but is really similar to just filtering or summarizing data.

# Let's use the Chicago Data Portal as an example using salary data: https://data.cityofchicago.org/Administration-Finance/Current-Employee-Names-Salaries-and-Position-Title/xzkq-xp2w

# We can see the documentation on the API endpoint here:
# https://dev.socrata.com/foundry/data.cityofchicago.org/xzkq-xp2w

# Let's try an example query based on the one provided by the docs:
salary_url <- "https://data.cityofchicago.org/resource/xzkq-xp2w.json?full_or_part_time=F&$limit=5000"

# The jsonlite library contains a function called read_json which will allow us to read the data directly into R
library(jsonlite)

salary <- read_json(salary_url, simplifyVector = TRUE)

salary %>%
  filter(salary_or_hourly == "Salary") %>%
  group_by(department) %>%
  summarize(mean_sal = mean(as.numeric(annual_salary), na.rm = T)) %>%
  arrange(desc(mean_sal)) %>%
  mutate(department = fct_reorder(department, mean_sal)) %>%
ggplot() +
  geom_point(aes(x = mean_sal, y = department)) +
  labs(
    title = "Chicago Salaries by Department",
    x = "Average Salary",
    y = "Department"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 6)
  )


cook <- read_json("https://datacatalog.cookcountyil.gov/resource/5mxh-trhm.json?&fiscal_year=2018&$limit=100000", simplifyVector = T)

cook %>%
  group_by(bureau) %>%
  summarize(
    mean_sal = mean(parse_number(base_pay), na.rm = T) * 4,
    count = n()
  ) %>%
  arrange(desc(mean_sal)) %>%
  mutate(bureau = fct_reorder(bureau, mean_sal)) %>%
  filter(row_number() < 30 | bureau == "COUNTY ASSESSOR") %>%
  ggplot() +
  geom_point(aes(x = mean_sal, y = bureau)) +
  labs(
    title = "Chicago Salaries by Department",
    x = "Average Salary",
    y = "Department"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 6)
  )

